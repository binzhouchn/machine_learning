{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.utils.data as Data\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import re\n",
    "import os\n",
    "from collections import Counter, OrderedDict\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy\n",
    "\n",
    "from m import f1_for_car, BOW, BasicModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "USE_CUDA=True\n",
    "EPOCH = 20           # 训练整批数据多少次\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.002         # 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 构造embedding字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.976 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "   Word Count: 100%|██████████| 53850/53850 [00:00<00:00, 402615.50it/s]\n",
      "Doc To Number: 100%|██████████| 53850/53850 [00:00<00:00, 156173.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# 以训练数据为例\n",
    "data_path_dir = 'data'\n",
    "data = pd.read_csv(os.path.join(data_path_dir,'cuishou_intent3.csv'),sep='\\t')\n",
    "data.columns = ['content','label']\n",
    "\n",
    "data_tmp = data.copy(deep=True)\n",
    "\n",
    "# label数值化(编码)\n",
    "d_ = {}\n",
    "for key, value in enumerate(set(data_tmp.label)):\n",
    "    d_[value] = key\n",
    "data_tmp['label'] = data_tmp['label'].apply(lambda x : d_.get(x))\n",
    "\n",
    "y_all = np.array(data_tmp.label.tolist())\n",
    "# 构造embedding字典\n",
    "bow = BOW(data_tmp.content.apply(jieba.lcut).tolist(), min_count=1, maxlen=30) # 长度补齐或截断固定长度30\n",
    "\n",
    "vocab_size = len(bow.word2idx)\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('data/ft_wv.txt')\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size+1,300))\n",
    "for key, value in bow.word2idx.items():\n",
    "    if key in word2vec.vocab: # Word2Vec训练得到的的实例需要word2vec.wv.vocab\n",
    "        embedding_matrix[value] = word2vec.get_vector(key)\n",
    "    else:\n",
    "        embedding_matrix[value] = [0] * embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save('save/embedding_matrix',arr=embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 数据处理 train_test_split 装入tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = copy.deepcopy(bow.doc2num)\n",
    "y = copy.deepcopy(y_all)\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "for train_idx, val_idx in skf.split(X,y):\n",
    "    pass\n",
    "\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "# 数据处理成tensor\n",
    "train_label_tensor = t.from_numpy(np.array(y_train)).long()\n",
    "train_content_tensor = t.from_numpy(np.array(X_train)).long()\n",
    "\n",
    "train_torch_dataset = Data.TensorDataset(train_content_tensor, train_label_tensor)\n",
    "train_loader = Data.DataLoader(\n",
    "        dataset=train_torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               # random shuffle for training\n",
    "        num_workers=8,              # subprocesses for loading data\n",
    "    )\n",
    "\n",
    "val_label_tensor = t.from_numpy(np.array(y_val)).long()\n",
    "val_content_tensor = t.from_numpy(np.array(X_val)).long()\n",
    "\n",
    "val_torch_dataset = Data.TensorDataset(val_content_tensor, val_label_tensor)\n",
    "val_loader = Data.DataLoader(\n",
    "        dataset=val_torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               # random shuffle for training\n",
    "        num_workers=8,              # subprocesses for loading data\n",
    "    )\n",
    "\n",
    "if USE_CUDA:\n",
    "    val_content_tensor = val_content_tensor.cuda()\n",
    "    val_label_tensor = val_label_tensor.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 构建Inception模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 配置文件\n",
    "class Config(object):\n",
    "    '''\n",
    "    并不是所有的配置都生效,实际运行中只根据需求获取自己需要的参数\n",
    "    '''\n",
    "\n",
    "    loss = 'multilabelloss'\n",
    "    model='LSTMText' \n",
    "    num_classes = 21 # 类别\n",
    "    embedding_dim = 300 # embedding大小\n",
    "    linear_hidden_size = 100 # 全连接层隐藏元数目\n",
    "    kmax_pooling = 30 # k\n",
    "    hidden_size = 128 # LSTM hidden size\n",
    "    num_layers= 2 # LSTM layers\n",
    "    inception_dim = 256 # inception的卷积核数\n",
    "    \n",
    "    # vocab_size = 11973 # num of chars\n",
    "    vocab_size = vocab_size # num of words \n",
    "    content_seq_len = 30 # 描述长度 word为100 char为200\n",
    "    static = False\n",
    "    use_pretrained_embedding = True\n",
    "    embedding_path = 'save/embedding_matrix.npy'\n",
    "\n",
    "opt = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Embed_Layer(BasicModule):\n",
    "\n",
    "    def __init__(self, embedding_matrix=None, opt=None):\n",
    "        super(Embed_Layer, self).__init__()\n",
    "        self.encoder = nn.Embedding(opt.vocab_size+1, opt.embedding_dim)\n",
    "        if opt.use_pretrained_embedding:\n",
    "#             self.encoder.weight.data.copy_(t.from_numpy(np.load(embedding_path))) # 方法一，加载np.save的npy文件\n",
    "#             self.encoder.weight.data.copy_(t.from_numpy(embedding_matrix)) # 方法二\n",
    "            self.encoder.weight = nn.Parameter(t.from_numpy(embedding_matrix).float(), requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class Ince(nn.Module):\n",
    "    def __init__(self, cin, co, relu=True, norm=True):\n",
    "        super(Ince, self).__init__()\n",
    "        assert (co % 4 == 0)\n",
    "        cos = [co // 4] * 4\n",
    "        self.activa = nn.Sequential()\n",
    "        if norm:\n",
    "            self.activa.add_module('norm', nn.BatchNorm1d(co))\n",
    "        if relu:\n",
    "            self.activa.add_module('relu', nn.ReLU(True))\n",
    "        self.branch1 = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(cin, cos[0], 1, stride=1)),\n",
    "        ]))\n",
    "        self.branch2 = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(cin, cos[1], 1)),\n",
    "            ('norm1', nn.BatchNorm1d(cos[1])),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('conv3', nn.Conv1d(cos[1], cos[1], 3, stride=1, padding=1)),\n",
    "        ]))\n",
    "        self.branch3 = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(cin, cos[2], 3, padding=1)),\n",
    "            ('norm1', nn.BatchNorm1d(cos[2])),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('conv3', nn.Conv1d(cos[2], cos[2], 5, stride=1, padding=2)),\n",
    "        ]))\n",
    "        self.branch4 = nn.Sequential(OrderedDict([\n",
    "            # ('pool',nn.MaxPool1d(2)),\n",
    "            ('conv3', nn.Conv1d(cin, cos[3], 3, stride=1, padding=1)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        result = self.activa(t.cat((branch1, branch2, branch3, branch4), 1))\n",
    "        return result\n",
    "\n",
    "\n",
    "class Dense_Layer(BasicModule):\n",
    "    def __init__(self, opt=opt):\n",
    "        super(Dense_Layer, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(200, opt.linear_hidden_size),\n",
    "            nn.BatchNorm1d(opt.linear_hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, opt.num_classes),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        reshaped = x.view(x.size(0), -1)\n",
    "        softmax = self.fc((reshaped))\n",
    "        return softmax\n",
    "    \n",
    "class Net_Main(BasicModule):\n",
    "    def __init__(self, opt=opt):\n",
    "        super(Net_Main, self).__init__()\n",
    "        self.embed_layer = Embed_Layer(embedding_matrix, opt)\n",
    "        # Inception layer\n",
    "        self.inception = nn.Sequential(\n",
    "            Ince(opt.embedding_dim, 200),\n",
    "            Ince(200, 200),\n",
    "            nn.MaxPool1d(opt.content_seq_len)\n",
    "        )\n",
    "        self.dense_layer = Dense_Layer(opt)\n",
    "    def forward(self, x):\n",
    "        content1 = self.embed_layer(x) # content1.size() (batch_size, seq_len, embed_dim)\n",
    "        content2 = self.inception(content1.permute(0,2,1))\n",
    "        res = self.dense_layer(content2)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 跑模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model, optimizer, loss_func\n",
    "m = Net_Main(opt)\n",
    "optimizer = t.optim.Adam(m.parameters(), lr=LR)   # optimize all lstm parameters;Adam比较好用\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted 适用于多分类\n",
    "if USE_CUDA:\n",
    "    m.cuda()\n",
    "    loss_func.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d3aa187b0845b1aee9a620fbab98ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc:  0.9520535216502509\n",
      "epoch 0....................................\n",
      "val acc:  0.9774205538004088\n",
      "epoch 1....................................\n",
      "val acc:  0.9842036796134548\n",
      "epoch 2....................................\n",
      "val acc:  0.9878275413491916\n",
      "epoch 3....................................\n",
      "val acc:  0.9843895186768259\n",
      "epoch 4....................................\n",
      "val acc:  0.9872700241590783\n",
      "epoch 5....................................\n",
      "val acc:  0.9891284147927895\n",
      "epoch 6....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-64:\n",
      "Process Process-63:\n",
      "Process Process-61:\n",
      "Traceback (most recent call last):\n",
      "Process Process-59:\n",
      "Process Process-58:\n",
      "Process Process-62:\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-57:\n",
      "Traceback (most recent call last):\n",
      "Process Process-60:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-61e29bd12f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 数据载入GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "it = 1\n",
    "for epoch in tqdm_notebook(range(EPOCH)):\n",
    "    for batch_id, (data, target) in enumerate(train_loader):\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda() # 数据载入GPU\n",
    "        output = m(data)\n",
    "        loss = loss_func(output, target)\n",
    "#         if it % 200 == 0:\n",
    "#             print('training loss: ', loss.cpu().data.numpy().tolist())\n",
    "#             print('training acc: ', accuracy_score(target.cpu().data.numpy(), np.argmax(output.cpu().data.numpy(),axis=1)))\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        it += 1\n",
    "    val_output = m(val_content_tensor)\n",
    "    print('val acc: ', accuracy_score(val_label_tensor.cpu().data.numpy(), np.argmax(val_output.cpu().data.numpy(),axis=1)))\n",
    "    print('epoch {}....................................'.format(epoch))\n",
    "    del val_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

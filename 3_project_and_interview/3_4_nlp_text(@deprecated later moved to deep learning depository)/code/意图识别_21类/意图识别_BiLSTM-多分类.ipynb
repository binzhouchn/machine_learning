{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch as t\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy\n",
    "\n",
    "from m import f1_for_car, BOW, BasicModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "USE_CUDA=True\n",
    "EPOCH = 20           # 训练整批数据多少次\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.002         # 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 构造embedding字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.952 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "   Word Count: 100%|██████████| 53850/53850 [00:00<00:00, 417347.92it/s]\n",
      "Doc To Number: 100%|██████████| 53850/53850 [00:00<00:00, 154139.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# 以训练数据为例\n",
    "data_path_dir = 'data'\n",
    "data = pd.read_csv(os.path.join(data_path_dir,'cuishou_intent3.csv'),sep='\\t')\n",
    "data.columns = ['content','label']\n",
    "\n",
    "data_tmp = data.copy(deep=True)\n",
    "\n",
    "# label数值化(编码)\n",
    "d_ = {}\n",
    "for key, value in enumerate(set(data_tmp.label)):\n",
    "    d_[value] = key\n",
    "data_tmp['label'] = data_tmp['label'].apply(lambda x : d_.get(x))\n",
    "\n",
    "y_all = np.array(data_tmp.label.tolist())\n",
    "# 构造embedding字典\n",
    "bow = BOW(data_tmp.content.apply(jieba.lcut).tolist(), min_count=1, maxlen=30) # 长度补齐或截断固定长度30\n",
    "\n",
    "vocab_size = len(bow.word2idx)\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('data/ft_wv.txt')\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size+1,300))\n",
    "for key, value in bow.word2idx.items():\n",
    "    if key in word2vec.vocab: # Word2Vec训练得到的的实例需要word2vec.wv.vocab\n",
    "        embedding_matrix[value] = word2vec.get_vector(key)\n",
    "    else:\n",
    "        embedding_matrix[value] = [0] * embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save('save/embedding_matrix',arr=embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 数据处理 train_test_split 装入tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = copy.deepcopy(bow.doc2num)\n",
    "y = copy.deepcopy(y_all)\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "for train_idx, val_idx in skf.split(X,y):\n",
    "    pass\n",
    "\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "# 数据处理成tensor\n",
    "train_label_tensor = torch.from_numpy(np.array(y_train)).long()\n",
    "train_content_tensor = torch.from_numpy(np.array(X_train)).long()\n",
    "\n",
    "train_torch_dataset = Data.TensorDataset(train_content_tensor, train_label_tensor)\n",
    "train_loader = Data.DataLoader(\n",
    "        dataset=train_torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               # random shuffle for training\n",
    "        num_workers=8,              # subprocesses for loading data\n",
    "    )\n",
    "\n",
    "val_label_tensor = torch.from_numpy(np.array(y_val)).long()\n",
    "val_content_tensor = torch.from_numpy(np.array(X_val)).long()\n",
    "\n",
    "val_torch_dataset = Data.TensorDataset(val_content_tensor, val_label_tensor)\n",
    "val_loader = Data.DataLoader(\n",
    "        dataset=val_torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               # random shuffle for training\n",
    "        num_workers=8,              # subprocesses for loading data\n",
    "    )\n",
    "\n",
    "if USE_CUDA:\n",
    "    val_content_tensor = val_content_tensor.cuda()\n",
    "    val_label_tensor = val_label_tensor.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 构建BiLSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 配置文件\n",
    "class Config(object):\n",
    "    '''\n",
    "    并不是所有的配置都生效,实际运行中只根据需求获取自己需要的参数\n",
    "    '''\n",
    "\n",
    "    loss = 'multilabelloss'\n",
    "    model='LSTMText' \n",
    "    num_classes = 21 # 类别\n",
    "    embedding_dim = 300 # embedding大小\n",
    "    linear_hidden_size = 1000 # 全连接层隐藏元数目\n",
    "    kmax_pooling = 30 # k\n",
    "    hidden_size = 128 # LSTM hidden size\n",
    "    num_layers= 2 # LSTM layers\n",
    "    inception_dim = 256 # inception的卷积核数\n",
    "    \n",
    "    # vocab_size = 11973 # num of chars\n",
    "    vocab_size = vocab_size # num of words \n",
    "    content_seq_len = 30 # 描述长度 word为100 char为200\n",
    "    static = False\n",
    "    use_pretrained_embedding = True\n",
    "    embedding_path = 'save/embedding_matrix.npy'\n",
    "\n",
    "opt = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 相当于把seq_len压缩成k个'词'\n",
    "# dim共三个维度，这里取2即seq_len那个维度，100->k\n",
    "def kmax_pooling(x, dim, k):\n",
    "    index = x.topk(k, dim = dim)[1].sort(dim = dim)[0]\n",
    "    return x.gather(dim, index)\n",
    "\n",
    "class Embed_Layer(BasicModule):\n",
    "\n",
    "    def __init__(self, embedding_matrix=None, opt=None):\n",
    "        super(Embed_Layer, self).__init__()\n",
    "        self.encoder = nn.Embedding(opt.vocab_size+1, opt.embedding_dim)\n",
    "        if opt.use_pretrained_embedding:\n",
    "#             self.encoder.weight.data.copy_(t.from_numpy(np.load(embedding_path))) # 方法一，加载np.save的npy文件\n",
    "#             self.encoder.weight.data.copy_(t.from_numpy(embedding_matrix)) # 方法二\n",
    "            self.encoder.weight = nn.Parameter(t.from_numpy(embedding_matrix).float(), requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class BiLSTMText(BasicModule): \n",
    "    def __init__(self, opt):\n",
    "        super(BiLSTMText, self).__init__()\n",
    "        self.model_name = 'BiLSTMText'\n",
    "        self.opt = opt\n",
    "\n",
    "        self.content_lstm =torch.nn.LSTM(input_size = opt.embedding_dim,\\\n",
    "                            hidden_size = opt.hidden_size,\n",
    "                            num_layers = opt.num_layers,\n",
    "                            bias = True,\n",
    "                            batch_first = False,\n",
    "                            dropout = 0.5, # dropout\n",
    "                            bidirectional = True\n",
    "                            )\n",
    "\n",
    "    def init_weights(self):\n",
    "        ih = (param.data for name, param in self.named_parameters() if 'weight_ih' in name)\n",
    "        hh = (param.data for name, param in self.named_parameters() if 'weight_hh' in name)\n",
    "        b = (param.data for name, param in self.named_parameters() if 'bias' in name)\n",
    "        for mat in ih:\n",
    "            nn.init.xavier_uniform_(mat)\n",
    "        for mat in hh:\n",
    "            nn.init.orthogonal_(mat)\n",
    "        for mat in b:\n",
    "            nn.init.constant_(mat, 0)\n",
    "    \n",
    "    def forward(self, content):\n",
    "        # torch.Size([128, 30, 150])\n",
    "        if self.opt.static:\n",
    "            content=content.detach()\n",
    "        \n",
    "        '''\n",
    "        lstm输入的时候需要转成(seq_len, batch, embedding_dim）这种维度（用permute转）<br>\n",
    "        output，每个时刻的LSTM网络的最后一层的输出，维度（seq_len, batch, hidden_size * num_directions）|双向lstm所以输出的hidden_size维度要乘以2<br>\n",
    "        lstm的输出为output, (hn, cn) 的元组<br>\n",
    "        这里取第一个就是output(100,64,256)，第二个是元组其中的第一个hn就是最后时刻的隐层状态hn(4,64,128)\n",
    "        这里的4就是(2层num_layers*双向)lstm得到\n",
    "        '''\n",
    "        content_out = self.content_lstm(content.permute(1,0,2))[0].permute(1,2,0)\n",
    "        content_conv_out = kmax_pooling((content_out), 2, self.opt.kmax_pooling)\n",
    "        conv_out = content_conv_out\n",
    "        return conv_out\n",
    "    \n",
    "class Dense_Layer(BasicModule):\n",
    "    def __init__(self, opt=opt):\n",
    "        super(Dense_Layer, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.opt.kmax_pooling*(self.opt.hidden_size*2), self.opt.linear_hidden_size),\n",
    "            torch.nn.Dropout(0.2), # dropout\n",
    "            torch.nn.BatchNorm1d(self.opt.linear_hidden_size),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(self.opt.linear_hidden_size, self.opt.num_classes),\n",
    "            torch.nn.Softmax(dim=-1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        reshaped = x.view(x.size(0), -1)\n",
    "        softmax = self.fc((reshaped))\n",
    "        return softmax\n",
    "    \n",
    "class Net_Main(BasicModule):\n",
    "    def __init__(self, opt=opt):\n",
    "        super(Net_Main, self).__init__()\n",
    "        self.embed_layer = Embed_Layer(embedding_matrix, opt)\n",
    "        self.bilstmtext = BiLSTMText(opt)\n",
    "        self.bilstmtext.init_weights() # 初始化LSTM权重参数\n",
    "        self.dense_layer = Dense_Layer(opt)\n",
    "    def forward(self, x):\n",
    "        content1 = self.embed_layer(x)\n",
    "        content2 = self.bilstmtext(content1)\n",
    "        res = self.dense_layer(content2)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 跑模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model, optimizer, loss_func\n",
    "m = Net_Main(opt)\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=LR)   # optimize all lstm parameters;Adam比较好用\n",
    "loss_func = torch.nn.CrossEntropyLoss()   # the target label is not one-hotted 适用于多分类\n",
    "if USE_CUDA:\n",
    "    m.cuda()\n",
    "    loss_func.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce502df663324a5cb3fc5b120d074c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc:  0.949080096636313\n",
      "epoch 0....................................\n",
      "val acc:  0.9619029920089203\n",
      "epoch 1....................................\n",
      "val acc:  0.9694294740754507\n",
      "epoch 2....................................\n",
      "val acc:  0.9766771975469244\n",
      "epoch 3....................................\n",
      "val acc:  0.9806727374094034\n",
      "epoch 4....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-47:\n",
      "Process Process-48:\n",
      "Process Process-43:\n",
      "Process Process-45:\n",
      "Traceback (most recent call last):\n",
      "Process Process-46:\n",
      "Process Process-42:\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-41:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "Process Process-44:\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-61e29bd12f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 数据载入GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "it = 1\n",
    "for epoch in tqdm_notebook(range(EPOCH)):\n",
    "    for batch_id, (data, target) in enumerate(train_loader):\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda() # 数据载入GPU\n",
    "        output = m(data)\n",
    "        loss = loss_func(output, target)\n",
    "#         if it % 200 == 0:\n",
    "#             print('training loss: ', loss.cpu().data.numpy().tolist())\n",
    "#             print('training acc: ', accuracy_score(target.cpu().data.numpy(), np.argmax(output.cpu().data.numpy(),axis=1)))\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        it += 1\n",
    "    val_output = m(val_content_tensor)\n",
    "    print('val acc: ', accuracy_score(val_label_tensor.cpu().data.numpy(), np.argmax(val_output.cpu().data.numpy(),axis=1)))\n",
    "    print('epoch {}....................................'.format(epoch))\n",
    "    del val_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
